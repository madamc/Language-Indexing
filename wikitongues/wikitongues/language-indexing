#!/usr/bin/env python

import scrapy
from scrapy.crawler import CrawlerProcess
import configparser
import os

from spiders.wikipedia_spider import WikipediaSpider

from language import Language

languages = [
    Language('sah', 'Sakha', 'https://en.wikipedia.org/wiki/Yakut_language'),
    Language('nrf', 'JÃ¨rriais', 'https://en.wikipedia.org/wiki/J%C3%A8rriais'),
    Language('qwe', 'Quechua', 'https://en.wikipedia.org/wiki/Quechuan_languages'),
    Language('nys', 'Nyungar', 'https://en.wikipedia.org/wiki/Nyungar_language'),
    Language('xho', 'Xhosa', 'https://en.wikipedia.org/wiki/Xhosa_language'),
    Language('dak', 'Sioux', 'https://en.wikipedia.org/wiki/Sioux_language')
]

process = CrawlerProcess(
    settings={
        "FEEDS": {
            "items.jl": {
                "format": "jl"
            }
        }
    }
)

config = configparser.ConfigParser()
config.read(os.path.join(os.path.dirname(__file__), 'config', 'indexing.cfg'))
sites = config.items('sites')
for site in sites:
    print(site)
    print(site[1])
print(sites)
print("Yer, this is cool!")
process.crawl(WikipediaSpider, languages)

process.start()
